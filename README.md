# CUB-200-2011 Classification
这是一个使用ResNet18模型在CUB-200-2011数据集上进行图像分类的项目。
我们也将其与随机初始化不使用预训练的模型进行对比。

# 项目描述
CUB-200-2011是一个包含200个鸟类物种的数据集,共包含11,788张图像。该项目使用PyTorch实现了一个图像分类模型,并进行了训练和评估。

# 数据集
本项目使用CUB-200-2011数据集,可以从以下地址下载:
https://www.vision.caltech.edu/datasets/cub_200_2011/
请将数据集解压到./CUB_200_2011目录下。
环境要求
	•	Python 3.7+
	•	PyTorch 1.13.0+
	•	torchvision
	•	numpy
	•	PIL
 
# 训练和评估模型
训练过程中,模型和损失曲线信息会保存在runs/目录下。

# 结果
在CUB-200-2011数据集上,本项目实现了以下性能:
我们对三组学习率进行对比：
learning_rates = [
    (5e-3, 5e-2),
    (1e-3, 1e-2),
    (5e-4, 5e-3)
]
(预训练模型参数的学习率,全连接层参数的学习率)

由输出数据可得，
当(预训练模型参数的学习率,全连接层参数的学习率) = (1e-3, 1e-2)时，验证集的准确率最高。
准确率第二高的是 (5e-4, 5e-3) ，最后是 (5e-3, 5e-2)。

	•	(5e-4, 5e-3) 准确率: 
	•	(5e-4, 5e-3) 准确率: xx%
	•	(5e-4, 5e-3) 准确率: 

epoch运行至11之后，Val Accuracy没有明显提升，会在小范围内波动。

因为对于没有预训练过的模型，采用了较高的学习率，但是准确率没有明显提升。

# 结论
## 使用/未使用预训练模型的区别
### 初始化权重
使用预训练模型:模型的大部分权重参数都是从预训练模型中获取的,已经学习到了一些有价值的特征表示。这样可以帮助模型更快地收敛,提高泛化性能。
未使用预训练模型:模型的权重参数都是随机初始化的,需要从头开始学习特征表示。这通常需要更长的训练时间才能达到同样的性能。
### 学习速度
使用预训练模型:由于初始权重已经较好,模型可以更快地学习到有价值的特征,训练速度更快。
未使用预训练模型:由于权重参数需要从头学习,训练过程通常会更加缓慢。
### 收敛速度
使用预训练模型:模型可以在较少的训练epoch下达到较好的性能,收敛更快。
未使用预训练模型:模型需要更多的训练epoch才能达到同样的性能,收敛较慢。
### 泛化性能
使用预训练模型:由于预训练模型已经学习到了一些有价值的通用特征,在迁移学习任务中通常能够表现更好,泛化性能更强。
未使用预训练模型:由于需要从头学习特征表示,泛化性能可能较弱。

总之,使用预训练模型可以大大加快模型训练的速度,并提高最终的性能,这在任务数据集较小或计算资源有限的情况下尤为重要。而未使用预训练模型则需要更多的训练时间和计算资源,但可以更好地适应特定任务的需求。

# Reference
	1	Wah, C., Branson, S., Welinder, P., Perona, P., & Belongie, S. (2011). The Caltech-UCSD Birds-200-2011 Dataset.
